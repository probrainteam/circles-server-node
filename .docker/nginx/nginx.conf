user nginx;
# We set worker_processes explicitly to 1 which is the default value.
# It is common practice to run 1 worker process per core. 
# For more about it, check Thread Pools in https://www.nginx.com/blog/thread-pools-boost-performance-9x/
# worker_processes는 추후 조정
worker_processes 1;
error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;
events {               
    # The worker_connections sets the maximum number of 
    # simultaneous connections that can be opened by a worker process (default=1024).   
    # worker_connections을 auto로 두기도 함  
    worker_connections  1024;
}
http {
    # Multipurpose Internet Mail Extensions = mime
    # 다목적 인터넷 메일 확장"이라는 뜻으로, 웹을 통해 여러 형태의 파일을 전달하는데 사용됨
    # (이메일과 함께 첨부한 파일을 텍스트 문자로 전환하여 email system으로 전달하기 위해 개발됨)
    # 기존의 UUEncode 방식: ASCII 파일만 가능
    # => MIME: Binary File(music, movie, word files,..) -> Text File
    # Content-type정보를 파일의 앞부분에 담음
    # https://developer.mozilla.org/ko/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # NGINX는 error page를 띄울 때 version명을 함께 명시
    # 버전명이 노출되는 경우 악의적인 사용자가 해당 버전의 취약점을 찔러 볼 수 있으므로
    # 버전명 출력을 막는다.
    server_tokens off;

    # upstream 정의
    # Upstream은 request를 요청하는 곳
    # NGINX가 앞단에서 받아 node로 request를 Proxy한다
    # 이런 의미에서 upstream
    upstream node-docker {
        # docker service 이름:port
        server node-dev:3000;
    }
    # 아래 upstream은 load balacing 예제
    # express1, express2, ...는 모두 docker-compose에서 정의된 docker services이름
    # PM2로 로드밸런싱을 진행하는데 NGINX를 통한 로드 밸런싱도 사용하는 것인지는
    # 추가적인 공부가 필요함

    # upstream docker-express {
    # least_conn;
    # server express1:3000 weight=10;
    # server express2:3000 weight=10;
    # server express3:3000 weight=10;
    # server express4:3000 weight=10;
    # }

    # HTTP
    # server {
    #     listen       80;
    #     server_name  localhost;
    #     # http(80)을 강제로 443으로 redirect
    #     # 현재 주석처리
    #     # location / { 
    #     #     return 301 https://localhost$request_uri;
    #     # }
    #     # @TODO :: ssl 설정 마치고 아래 삭제
    #      location / {
    #         proxy_pass         http://node-docker;
    #         proxy_redirect     off;
    #         proxy_set_header   Host $host;
    #         proxy_set_header   X-Real-IP $remote_addr;
    #         proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;          
    #     }
    # }
    # # HTTPS
    server {
        # listen 443 ssl; # @TODO :: ssl 설정이 완료된 경우 변경
        listen 443;
        server_name localhost;

        # proxy_pass : 위에서 정의한 upstream 이름
        location / {
            proxy_pass         http://node-docker; 
            proxy_redirect     off;
            proxy_set_header   Host $host;
            proxy_set_header   X-Real-IP $remote_addr;
            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;          
        }
    }
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
    access_log  /var/log/nginx/access.log  main;

    # 파일 전송
    # @TODO :: mime, content-type 조정과 함께 sendfile x                   
    sendfile        on;

    # keepalive {connection수} : nginx에서 캐싱할 커넥션 수.
    # 이 숫자를 초과한 연결 요청이 들어오면 LRU에 따라 과거 커넥션부터 해제한다. 
    # 너무 많이 설정하면 자원이 너무 많이 점유되니 상황에 따라 조정이 필요하다. 
    
    # 클라이언트에서 커넥션을 유지하는 시간. 
    # 길게 잡으면 클라이언트 입장에서는 좋지만, 서버에서는 요청도 없으면서 커넥션을 너무 많이 맺고 있게 된다. 
    # 최신 브라우저들은 XHR을 보통 4~6개까지 동시 사용할 수 있으니 짧게 잡는게 좋다. 
    # 보통 한 페이지 로딩하는 데 걸리는 시간보다 조금 길게 잡으면 된다.
                                                   
    keepalive_timeout  10;                                                                  
    include /etc/nginx/conf.d/*.conf;           
}